# OpenAI API Configuration
VITE_OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenRouter API Configuration (for Mistral and other models)
VITE_OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here

# Anthropic API Configuration (for Claude)
VITE_ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Local Provider Configuration (Ollama/LocalAI)
VITE_LOCAL_OPENAI_BASEURL=http://localhost:11434/v1
VITE_LOCAL_OPENAI_MODEL=llama3.1:8b-instruct

# Custom Provider Configuration (OpenAI-compatible endpoints)
VITE_CUSTOM_OPENAI_BASEURL=https://your-endpoint.example.com/v1
VITE_CUSTOM_OPENAI_MODEL=custom-model
VITE_CUSTOM_OPENAI_API_KEY=sk-your-custom-api-key-here

# Instructions:
# 1. Copy this file to .env
# 2. Replace the API keys and endpoints with your actual values:
#    - OpenAI API key for ChatGPT
#    - OpenRouter API key for Mistral and other models
#    - Anthropic API key for Claude
#    - Local endpoint URL and model for Ollama/LocalAI
#    - Custom endpoint configuration for other OpenAI-compatible APIs
# 3. The .env file is already in .gitignore and won't be committed to the repository